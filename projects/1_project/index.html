<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>RobustMFit.jl | Manuel Stapper</title> <meta name="author" content="Manuel Stapper"> <meta name="description" content="Robust Fitting of Distributions"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/favicon.png"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://manuelstapper.github.io/projects/1_project/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Manuel </span>Stapper</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about</a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects</a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories</a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">teaching</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">RobustMFit.jl</h1> <p class="post-description">Robust Fitting of Distributions</p> </header> <article> <h2 id="introduction">Introduction</h2> <p>In practice, we often come across unusual observations in a sample. Robust statistics offers great tools to ignore or limit the influence of such observations on an estimate. This project deals with a famous class of robust estimators: M-estimators. Although initially developed for location estimation without distributional assumption, we limit to the case where a distribution is assumed and especially focus on the case of skewed or in more general terms asymmetric distributions. Standard M-estimation techniques frequently yield biased estimates that need to be corrected. In the following, I am going to give you an overview of a Julia package that was developed to fit distributions to i.i.d. samples using M-estimators. Two bias correction approaches are included: an established method and a novel appraoch.</p> <p>To describe the bias corrections, let us consider a simple random sample \(X_1, …, X_n\). The expectation of \(X_i\) can be estimated by minimizing \[ \sum_{i = 1}^n \rho\left(\frac{X_i - \mu}{\sigma}\right) \]with respect to \(\mu\), where \(\sigma\) is the known or robustly estimated standard deviation of \(X_i\). The function \(\rho\) is a general loss function that attains its minimum at zero. Taking the derivative transforms the optimiztsation problem into the estimation equation \[ \sum_{i = 1}^n \psi\left(\frac{X_i - \mu}{\sigma}\right) = 0 \]where \(\psi\) is the derivative of \(\rho\). Whenever \(\psi\) is bounded in absolute value, the resulting estimator is robust. Inserting \(w(z) = \psi(z)/z\), we can further rewrite the estimation equation as fixed point equation \[ \mu = \frac{\sum_{i = 1}^n w(Z_i)X_i}{\sum_{i = 1}^n w(Z_i)} \]with \(Z_i = \frac{X_i - \mu}{\sigma}\). In robust statistics, we typically select a loss function that depends on the choice of a tuning constant that controls the trade-off between robustness and efficiency.</p> <h2 id="established-bias-correction">Established Bias Correction</h2> <p>Popular choices of the loss function are symmetric, which means that deviations from the mean \(\mu\) to both sides are considered equally “bad”. However, for skewed distributions deviations to one side are more likely than dewviations to the other side, which causes a bias. Mathematically, we find a bias whenever \[ \operatorname{E}<em>0\left(\psi\left(\frac{X_i - \mu}{\sigma}\right)\right) \ne 0 \]where the expectation is taken with respect to true parameters \(\theta_0\). The established correction approach simply subtracts a correction constant \[ c</em>\theta = \operatorname{E}<em>\theta\left(\psi\left(\frac{X_i - \mu}{\sigma}\right)\right) \]in the estimation equation, i.e. \[ \sum</em>{i = 1}^n \psi\left(\frac{X_i - \mu}{\sigma}\right) - c_\theta = 0\text{ .} \]To clarify, let us assume that \(X_i \sim \text{Pois}(\lambda)\). Then, the estimation equation becomes \[ \sum_{i = 1}^n \psi\left(\frac{X_i - \lambda}{\sqrt{\lambda}}\right) - c_\lambda = 0\text{ .} \]To avoid repeated compuatation of \(c_\lambda\) and to gain numerical stability, the estimation equation can be solved iteratively by keeping \(c_\lambda\) and the standard deviation \(\sqrt{\lambda}\) constant from the previous iteration.</p> <p>In this example, the expectation coincides with the parameter. If we want to fit a distribution that does not have this property, we have two esitmation options. Let $X_i$ now follow a Geometric distribution, such that \(\operatorname{E}(X_i) = \frac{1 - p}{p}\). For notational brevity, let \(\mu(p)\) be the expectation and \(\sigma(p)\) the standard deviation of the Geometric distribution. Then, we have \[ \sum_{i = 1}^n \psi\left(\frac{X_i - \mu(p)}{\sigma(p)}\right) - c_p = 0\text{ .} \]and can solve for \(p\) directly. We will refer to the approach as the “direct approach”. Alternatively, we can solve for \(\mu(p)\) and translate the mean to a parameter estimate for \(p\), which we will call the “moment based approach”.</p> <p>Both example distributions are parametrized by one parameter. If we want to fit a distribution with a parameter vector \(\theta\in\mathbb{R}^p\), we can extend the estimation equation to higher powers of \(X_i\), i.e. \(X_i, X_i^2, … X_i^p\). The \(p\) estimation equations then become \[ \sum_{i = 1}^n \psi\left(\frac{X_i^j - \mu_j(\theta)}{\sigma_j(\theta)}\right) - c_{\theta, j} = 0 \]for \(j = 1, …, p\) where \(\mu_j(\theta)\) is the expectation of \(X_i^j\) and \(\sigma_j(\theta)\) its standard deviation. The choice of the function \(\psi\) and its tuning constant may be selected differently for the single estimation equations.</p> <h2 id="novel-bias-correction">Novel Bias Correction</h2> <p>Instead of using symmetric functions \(\rho\), \(\psi\) or \(w\), and including a correction term, we can use asymmetric functions. The bias is tackled similarly as in the established approach by making the estimation equation zero for true parameters. The idea is to use different tuning constants for deviations to the two sides. To clarify, we simply use one tuning constant for observations that are greater that the mean (upper tuning constant) and another tuning constant for observations smaller that the mean (lower tuning constant). Keeping one of them fixed, we select the other tuning constant accordingly. In the case of one-parameter distributions, we solve \[ \operatorname{E}\left(\psi\left(\frac{X_i - \mu(\theta)}{\sigma(\theta)}\right)\right) = 0 \]either for the lower tuning constant keeping the upper tuning constant or vice versa. For distributions with more than one parameter, we again simply set up multiple estimation equations considering the powers \(X_i, X_i^2, …, X_i^p\).</p> <p>Let us now take a look at the Julia package that offers M-estimation of (almost) any distribution. The goal of the package was to provide the methods in a user-friendly way, such that parameters of any distribution can be estimated with any choice of loss function.</p> <p>The package is available on my <a href="https://github.com/ManuelStapper/RobustMFit.jl" rel="external nofollow noopener" target="_blank">GitHub repository</a> and the general Julia package repository. It can be installed and activated by running</p> <div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">using</span> <span class="n">Pkg</span>
<span class="n">Pkg</span><span class="o">.</span><span class="n">add</span><span class="x">(</span><span class="s">"RobustMFit"</span><span class="x">)</span>
<span class="k">using</span> <span class="n">RobustMFit</span>
</code></pre></div></div> <p>Also activating the Distributions.jl package lets us now sample from a distribution, say the Poisson</p> <div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">d</span> <span class="o">=</span> <span class="n">Poisson</span><span class="x">(</span><span class="mi">10</span><span class="x">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">rand</span><span class="x">(</span><span class="n">d</span><span class="x">,</span> <span class="mi">100</span><span class="x">)</span>
</code></pre></div></div> <p>and then estimate the parameter by</p> <div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">Mfit</span><span class="x">(</span><span class="n">x</span><span class="x">,</span> <span class="n">d</span><span class="x">,</span> <span class="n">Huber</span><span class="x">(</span><span class="mf">1.345</span><span class="x">))</span>
</code></pre></div></div> <p>The three arguments are <code class="language-plaintext highlighter-rouge">x</code>, the sample, <code class="language-plaintext highlighter-rouge">d</code>, the distribution we’d like to fit, where the parameters chosen are used as initial values for the estimation and <code class="language-plaintext highlighter-rouge">Huber(1.345)</code> specifies the type of functions we select. Here we use Huber’s functions with tuning constant 1.345. Currently, four types of functions are implemented in the package: Huber, Tukey, Andrew and Hampel.</p> <p>By default, the function carries out the moment based approach solving the \(\psi\)-function estimation equation. It is accounted for a potential bias by keeping the upper tuning constant fixed and updating the lower tuning constant in iterations. If we choose to change the estimation settings, we can change the keyword arguments <code class="language-plaintext highlighter-rouge">type</code>, <code class="language-plaintext highlighter-rouge">MM</code> and <code class="language-plaintext highlighter-rouge">biasCorr</code>. For example</p> <div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">Mfit</span><span class="x">(</span><span class="n">x</span><span class="x">,</span> <span class="n">d</span><span class="x">,</span> <span class="n">Huber</span><span class="x">(</span><span class="mf">1.345</span><span class="x">),</span> <span class="n">type</span> <span class="o">=</span> <span class="o">:</span><span class="n">ρ</span><span class="x">,</span> <span class="n">MM</span> <span class="o">=</span> <span class="nb">false</span><span class="x">,</span> <span class="n">biasCorr</span> <span class="o">=</span> <span class="o">:</span><span class="n">L</span><span class="x">)</span>
</code></pre></div></div> <p>The argument <code class="language-plaintext highlighter-rouge">type</code> can be either <code class="language-plaintext highlighter-rouge">:ρ</code>, <code class="language-plaintext highlighter-rouge">:ψ</code> or <code class="language-plaintext highlighter-rouge">:w</code>, where each can be put in either as symbol or as string <code class="language-plaintext highlighter-rouge">"ρ"</code>, <code class="language-plaintext highlighter-rouge">"ψ"</code> and <code class="language-plaintext highlighter-rouge">"w"</code>. The boolean argument <code class="language-plaintext highlighter-rouge">MM</code> is set to <code class="language-plaintext highlighter-rouge">false</code> for the direct estimation approach and to <code class="language-plaintext highlighter-rouge">true</code> for the moment based approach. The bias correction technique is either <code class="language-plaintext highlighter-rouge">:C</code> for the correction term, <code class="language-plaintext highlighter-rouge">:L</code> and <code class="language-plaintext highlighter-rouge">:U</code> for asymmetric estimation functions, where <code class="language-plaintext highlighter-rouge">:L</code> indicates that the lower tuning constant shall be updated, or as <code class="language-plaintext highlighter-rouge">:N</code> for no correction.</p> <p>The asymptotic variance can then be computed and the relative asymptotic efficiency (compared to ML estimation) by</p> <div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">est</span> <span class="o">=</span> <span class="n">Mfit</span><span class="x">(</span><span class="n">x</span><span class="x">,</span> <span class="n">d</span><span class="x">,</span> <span class="n">Huber</span><span class="x">(</span><span class="mf">1.345</span><span class="x">),</span> <span class="n">type</span> <span class="o">=</span> <span class="o">:</span><span class="n">ρ</span><span class="x">,</span> <span class="n">MM</span> <span class="o">=</span> <span class="nb">false</span><span class="x">,</span> <span class="n">biasCorr</span> <span class="o">=</span> <span class="o">:</span><span class="n">L</span><span class="x">)</span>
<span class="n">AVar</span><span class="x">(</span><span class="n">Poisson</span><span class="x">(</span><span class="n">est</span><span class="x">),</span> <span class="n">Huber</span><span class="x">(</span><span class="mf">1.345</span><span class="x">),</span> <span class="o">:</span><span class="n">L</span><span class="x">)</span>
<span class="n">RAE</span><span class="x">(</span><span class="n">Poisson</span><span class="x">(</span><span class="n">est</span><span class="x">),</span> <span class="n">Huber</span><span class="x">(</span><span class="mf">1.345</span><span class="x">),</span> <span class="o">:</span><span class="n">L</span><span class="x">)</span>
</code></pre></div></div> <p>More details on what happens in the background during estimation will follow soon</p> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2024 Manuel Stapper. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="/assets/js/common.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>